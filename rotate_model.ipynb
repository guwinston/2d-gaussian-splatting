{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load gaussian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "from gaussian_renderer import render\n",
    "from gaussian_renderer import GaussianModel\n",
    "from utils.graphics_utils import focal2fov, fov2focal\n",
    "from utils.camera_utils import Camera\n",
    "from scene.dataset_readers import CameraInfo\n",
    "\n",
    "def load_model(model_path, sh_degree=3):\n",
    "    with torch.no_grad():\n",
    "        gaussians  = GaussianModel(sh_degree)\n",
    "        gaussians.load_ply(model_path)\n",
    "        print(f\"gaussain model has been load from {model_path}\")\n",
    "        return gaussians\n",
    "\n",
    "\n",
    "def load_camera_infos(camera_path):\n",
    "    with open(camera_path) as f:\n",
    "        cameras_data = json.load(f)\n",
    "\n",
    "    cameras = []\n",
    "    for cam_idx in range(len(cameras_data)):\n",
    "        rotation = np.array(cameras_data[cam_idx]['rotation'])\n",
    "        position = np.array(cameras_data[cam_idx]['position'])\n",
    "        height = cameras_data[cam_idx]['height']\n",
    "        width  = cameras_data[cam_idx]['width']\n",
    "        focalx = cameras_data[cam_idx]['fx']\n",
    "        focaly = cameras_data[cam_idx]['fy']\n",
    "        id     = cameras_data[cam_idx]['id']\n",
    "        name   = cameras_data[cam_idx]['img_name']\n",
    "\n",
    "        C2W = np.zeros((4,4))\n",
    "        C2W[:3, :3] = rotation\n",
    "        C2W[:3,  3] = position\n",
    "        C2W[3,   3] = 1\n",
    "        W2C = np.linalg.inv(C2W)\n",
    "        T = W2C[:3, 3]\n",
    "        R = W2C[:3, :3].transpose()\n",
    "        \n",
    "        fov_y = focal2fov(focaly, height)\n",
    "        fov_x = focal2fov(focalx, width)\n",
    "        image = None\n",
    "\n",
    "        # CameraInfo 和 Camera的输入的R和T需要特别注意，R为camera to world，T为world to camera\n",
    "        # camera = Camera(colmap_id=id, R=R, T=T, FoVx=fov_x, FoVy=fov_y, image=image, gt_alpha_mask=None,\n",
    "        #                 image_name=name, uid=id)\n",
    "        camera = CameraInfo(uid=cam_idx, R=R, T=T, FovY=fov_y, FovX=fov_x, image=image,\n",
    "                              image_path=None, image_name=name, width=width, height=height)\n",
    "        cameras.append(camera)\n",
    "    print(f\"{len(cameras)} cameras have been loaded from {camera_path}\")\n",
    "    return cameras\n",
    "\n",
    "def render_image(model, camera, image_save_path=None, white_backgrund=False):\n",
    "    with torch.no_grad():\n",
    "        pipeline   = {\"debug\":False, \"compute_cov3D_python\":False, \"convert_SHs_python\":False, \"depth_ratio\":0}\n",
    "        pipeline   = SimpleNamespace(**pipeline)\n",
    "        background = torch.tensor([0, 0, 0] if not white_backgrund else [1,1,1], dtype=torch.float32, device=\"cuda\")\n",
    "        rendering = render(camera, model, pipeline, background)[\"render\"]\n",
    "        if image_save_path is not None:\n",
    "            torchvision.utils.save_image(rendering,image_save_path)\n",
    "    return rendering.permute(1,2,0).cpu().numpy()\n",
    "camera_path = \"output/garden/cameras.json\"\n",
    "model_path = \"output/garden/point_cloud/iteration_30000/point_cloud.ply\"\n",
    "model = load_model(model_path, sh_degree=3)\n",
    "cameras_infos = load_camera_infos(camera_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# render one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "cam_info = cameras_infos[0]\n",
    "camera = Camera(colmap_id=cam_info.uid, R=cam_info.R, T=cam_info.T, \n",
    "                FoVx=cam_info.FovX, FoVy=cam_info.FovY, \n",
    "                image=torch.zeros((3,cam_info.height, cam_info.width)), gt_alpha_mask=None,\n",
    "                image_name=cam_info.image_name, uid=id)\n",
    "origianl_image = render_image(model, camera, white_backgrund=False) # hwc\n",
    "plt.imshow(origianl_image)\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize in open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_camera_frustum(pose, fov_rad, aspect, near, far):\n",
    "    h_near = 2 * math.tan(fov_rad / 2) * near\n",
    "    w_near = h_near * aspect\n",
    "    h_far = 2 * math.tan(fov_rad / 2) * far\n",
    "    w_far = h_far * aspect\n",
    "    \n",
    "    # 定义视锥在相机坐标系中的8个角点\n",
    "    # 相机位于原点，朝向正Z方向\n",
    "    points_camera = np.array([\n",
    "        [0, 0, 0],  # 相机位置\n",
    "        \n",
    "        [-w_near/2,  h_near/2, near],\n",
    "        [ w_near/2,  h_near/2, near],\n",
    "        [ w_near/2, -h_near/2, near],\n",
    "        [-w_near/2, -h_near/2, near],\n",
    "        \n",
    "        [-w_far/2,  h_far/2, far],\n",
    "        [ w_far/2,  h_far/2, far],\n",
    "        [ w_far/2, -h_far/2, far],\n",
    "        [-w_far/2, -h_far/2, far],\n",
    "    ], dtype=float)  # 确保数组为浮点类型\n",
    "\n",
    "    # 将视锥的点从相机坐标系转换到世界坐标系\n",
    "    # 使用位姿矩阵的逆（从相机到世界）\n",
    "    pose_inv = np.linalg.inv(pose)\n",
    "    points_world_homog = pose_inv @ np.hstack((points_camera, np.ones((points_camera.shape[0], 1)))).T\n",
    "    points_world = points_world_homog[:3].T\n",
    "    \n",
    "    # 定义视锥的边（线段连接）\n",
    "    lines = [\n",
    "        [0,1], [0,2], [0,3], [0,4],  # 从相机到近裁剪面的四个角点\n",
    "        [1,2], [2,3], [3,4], [4,1],  # 近裁剪面的边界\n",
    "        [1,5], [2,6], [3,7], [4,8],  # 连接近裁剪面和远裁剪面的边\n",
    "        [5,6], [6,7], [7,8], [8,5]   # 远裁剪面的边界\n",
    "    ]\n",
    "    \n",
    "    # 定义视锥边的颜色，例如蓝色\n",
    "    colors = [[0, 0, 1] for _ in lines]\n",
    "    \n",
    "    # 创建视锥的 LineSet\n",
    "    frustum = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(points_world),\n",
    "        lines=o3d.utility.Vector2iVector(lines)\n",
    "    )\n",
    "    frustum.colors = o3d.utility.Vector3dVector(colors)\n",
    "    \n",
    "    return frustum\n",
    "\n",
    "@torch.no_grad()\n",
    "def visualize_camera_and_gaussians(cameras, model):\n",
    "    points = model.get_xyz.detach().cpu().numpy()\n",
    "    colors = model._features_dc.detach().cpu().numpy().reshape(points.shape[0], -1)\n",
    "    colors = colors * 0.28209479177387814 + 0.5\n",
    "    print(\"model has {} gaussians\".format(len(points)))\n",
    "    print(\"points min {}, max {}, center {}\".format(points.min(0), points.max(0), points.mean(0)))\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    base_point = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.5, origin=[0,0,0])\n",
    "    geometries = [pcd]\n",
    "\n",
    "    for camera in tqdm(cameras):\n",
    "        intrinsic = o3d.camera.PinholeCameraIntrinsic(\n",
    "            width=camera.image_width,\n",
    "            height=camera.image_height,\n",
    "            fx=fov2focal(camera.FoVx, camera.image_width),\n",
    "            fy=fov2focal(camera.FoVy, camera.image_height),\n",
    "            cx=camera.image_width/2,\n",
    "            cy=camera.image_height/2\n",
    "        )\n",
    "        \n",
    "        position = np.array(camera.T)               # W2C\n",
    "        rotation = np.array(camera.R).transpose()   # W2C\n",
    "        W2C = np.eye(4)\n",
    "        W2C[:3, :3] = rotation\n",
    "        W2C[:3,  3] = position\n",
    "        C2W = np.linalg.inv(W2C)\n",
    "\n",
    "        camera_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.5, origin=[0,0,0])\n",
    "        camera_frame.transform(C2W)\n",
    "        \n",
    "        frustum = o3d.geometry.LineSet.create_camera_visualization(\n",
    "            intrinsic.width, intrinsic.height, intrinsic.intrinsic_matrix, W2C, scale=2.0\n",
    "        )\n",
    "        # frustum = create_camera_frustum(W2C, camera.FoVy, camera.image_width / camera.image_height, 0.1, 2)\n",
    "\n",
    "        geometries.append(camera_frame)\n",
    "        geometries.append(frustum)\n",
    "\n",
    "    o3d.visualization.draw_geometries(geometries, point_show_normal=True, height=1080, width=1920)\n",
    "cameras = [Camera(colmap_id=cam_info.uid, R=cam_info.R, T=cam_info.T, \n",
    "                FoVx=cam_info.FovX, FoVy=cam_info.FovY, \n",
    "                image=torch.zeros((3,cam_info.height, cam_info.width)), gt_alpha_mask=None,\n",
    "                image_name=cam_info.image_name, uid=id) for cam_info in cameras_infos]\n",
    "# visualize_camera_and_gaussians(cameras, model)\n",
    "visualize_camera_and_gaussians([cameras[0]], model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit: Rotate gaussain model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some function to rotate gaussian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "from e3nn import o3\n",
    "from einops import einsum\n",
    "from scipy.spatial.transform import Rotation\n",
    "from utils.general_utils import build_rotation\n",
    "\n",
    "@torch.no_grad()\n",
    "def rotate_xyz(gaussians, rotmat):\n",
    "    new_xyz = gaussians.get_xyz\n",
    "    mean_xyz = torch.mean(new_xyz,0)\n",
    "    new_xyz = new_xyz - mean_xyz\n",
    "    new_xyz = new_xyz @ rotmat.T\n",
    "    gaussians._xyz = new_xyz + mean_xyz\n",
    "\n",
    "@torch.no_grad()\n",
    "def rotate_rot(gaussians, rotmat):\n",
    "    new_rotation = build_rotation(gaussians._rotation)\n",
    "    new_rotation = rotmat @ new_rotation\n",
    "    new_quat = np.array(Rotation.from_matrix(new_rotation.detach().cpu().numpy()).as_quat())\n",
    "    new_quat[:, [0,1,2,3]] = new_quat[:, [3,0,1,2]] # xyzw -> wxyz\n",
    "    gaussians._rotation = torch.from_numpy(new_quat).to(gaussians._rotation.device).float()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def rotate_shs(gaussians, rotmat):\n",
    "    # reference: https://github.com/graphdeco-inria/gaussian-splatting/issues/176#issuecomment-2147223570\n",
    "    shs_feat = gaussians._features_rest\n",
    "    ## rotate shs\n",
    "    P = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0]], dtype=np.float32) # switch axes: yzx -> xyz\n",
    "    permuted_rotmat = np.linalg.inv(P) @ rotmat.to('cpu').numpy() @ P\n",
    "    rot_angles = o3._rotation.matrix_to_angles(torch.from_numpy(permuted_rotmat))\n",
    "\n",
    "    # Construction coefficient\n",
    "    D_1 = o3.wigner_D(1, rot_angles[0], - rot_angles[1], rot_angles[2]).to(shs_feat.device).float()\n",
    "    D_2 = o3.wigner_D(2, rot_angles[0], - rot_angles[1], rot_angles[2]).to(shs_feat.device).float()\n",
    "    D_3 = o3.wigner_D(3, rot_angles[0], - rot_angles[1], rot_angles[2]).to(shs_feat.device).float()\n",
    "\n",
    "    #rotation of the shs features\n",
    "    one_degree_shs = shs_feat[:, 0:3]\n",
    "    one_degree_shs = einops.rearrange(one_degree_shs, 'n shs_num rgb -> n rgb shs_num')\n",
    "    one_degree_shs = einsum(\n",
    "            D_1,\n",
    "            one_degree_shs,\n",
    "            \"... i j, ... j -> ... i\",\n",
    "        )\n",
    "    one_degree_shs = einops.rearrange(one_degree_shs, 'n rgb shs_num -> n shs_num rgb')\n",
    "    shs_feat[:, 0:3] = one_degree_shs\n",
    "\n",
    "    two_degree_shs = shs_feat[:, 3:8]\n",
    "    two_degree_shs = einops.rearrange(two_degree_shs, 'n shs_num rgb -> n rgb shs_num')\n",
    "    two_degree_shs = einsum(\n",
    "            D_2,\n",
    "            two_degree_shs,\n",
    "            \"... i j, ... j -> ... i\",\n",
    "        )\n",
    "    two_degree_shs = einops.rearrange(two_degree_shs, 'n rgb shs_num -> n shs_num rgb')\n",
    "    shs_feat[:, 3:8] = two_degree_shs\n",
    "\n",
    "    three_degree_shs = shs_feat[:, 8:15]\n",
    "    three_degree_shs = einops.rearrange(three_degree_shs, 'n shs_num rgb -> n rgb shs_num')\n",
    "    three_degree_shs = einsum(\n",
    "            D_3,\n",
    "            three_degree_shs,\n",
    "            \"... i j, ... j -> ... i\",\n",
    "        )\n",
    "    three_degree_shs = einops.rearrange(three_degree_shs, 'n rgb shs_num -> n shs_num rgb')\n",
    "    shs_feat[:, 8:15] = three_degree_shs\n",
    "\n",
    "    gaussians._features_rest = shs_feat.float()\n",
    "\n",
    "def rotate_camera(cam_position, cam_rotation, obj_position, rotmat):\n",
    "    translated_position = cam_position - obj_position\n",
    "    translated_position = translated_position @ rotmat.T\n",
    "    new_cam_position = translated_position + obj_position\n",
    "    new_cam_rotation = rotmat @ cam_rotation\n",
    "    return new_cam_position, new_cam_rotation\n",
    "\n",
    "\n",
    "def rotate_o3dmesh(mesh_path, mesh_save_path, rotation_matrix, model_center):\n",
    "    import open3d as o3d\n",
    "    mesh_dir = os.path.dirname(mesh_path)\n",
    "    mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "    assert rotation_matrix.shape == (3, 3), \"Rotation matrix must be 3x3.\"\n",
    "    vertices = np.asarray(mesh.vertices)\n",
    "    vertices -= model_center\n",
    "    rotated_vertices = np.dot(vertices, rotation_matrix.T)\n",
    "    rotated_vertices += model_center\n",
    "    mesh.vertices = o3d.utility.Vector3dVector(rotated_vertices)\n",
    "    o3d.io.write_triangle_mesh(mesh_save_path, mesh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. rotate gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "angle_degrees = -120\n",
    "angle_radians = np.deg2rad(angle_degrees)\n",
    "rotation = Rotation.from_euler('x', angle_radians)\n",
    "rotation = rotation.as_matrix() \n",
    "# rotation = Rotation.from_euler('y', np.deg2rad(-3)).as_matrix() @ rotation\n",
    "# rotation = Rotation.from_euler('x', np.deg2rad(-10)).as_matrix() @ rotation\n",
    "rotmat = torch.from_numpy(rotation).to(model.get_xyz.device).float()\n",
    "\n",
    "rotated_model = deepcopy(model)\n",
    "rotate_xyz(rotated_model, rotmat)\n",
    "rotate_rot(rotated_model, rotmat)\n",
    "rotate_shs(rotated_model, rotmat)\n",
    "\n",
    "rotate_gaussians_image = render_image(rotated_model, camera, white_backgrund=False) # hwc\n",
    "# plt.imshow(rotate_gaussians_image)\n",
    "# plt.draw()\n",
    "\n",
    "# cameras = [camera]\n",
    "# visualize_camera_and_gaussians(cameras, rotated_model)\n",
    "rotated_model.save_ply(\"output/garden_aligned_xy/point_cloud/iteration_30000/point_cloud.ply\")\n",
    "mesh_path = \"output/garden/train/ours_30000/fuse_unbounded_post.ply\"\n",
    "mesh_save_path = \"output/garden_aligned_xy/train/ours_30000/aligned_xy_mesh.ply\"\n",
    "rotate_o3dmesh(mesh_path, mesh_save_path, rotation, model_center=torch.mean(model.get_xyz, dim=0).detach().cpu().numpy())\n",
    "with open(camera_path) as f:\n",
    "    cameras_data = json.load(f)\n",
    "    model_center = torch.mean(model.get_xyz, dim=0).detach().cpu().numpy()\n",
    "    for cam_idx in range(len(cameras_data)):\n",
    "        cam_position = np.array(cameras_data[cam_idx][\"position\"])\n",
    "        cam_rotation = np.array(cameras_data[cam_idx][\"rotation\"])\n",
    "        new_cam_position, new_cam_rotation = rotate_camera(cam_position, cam_rotation, model_center, rotation)\n",
    "        cameras_data[cam_idx][\"position\"] = new_cam_position.tolist()\n",
    "        cameras_data[cam_idx][\"rotation\"] = new_cam_rotation.tolist()\n",
    "\n",
    "with open(\"output/garden_aligned_xy/cameras.json\", 'w') as f:\n",
    "    json.dump(cameras_data, f)\n",
    "new_cameras_infos = load_camera_infos(\"output/garden_aligned_xy/cameras.json\")\n",
    "new_cam_info = new_cameras_infos[0]\n",
    "new_camera = Camera(colmap_id=new_cam_info.uid, R=new_cam_info.R, T=new_cam_info.T, \n",
    "                FoVx=new_cam_info.FovX, FoVy=new_cam_info.FovY, \n",
    "                image=torch.zeros((3,new_cam_info.height, new_cam_info.width)), gt_alpha_mask=None,\n",
    "                image_name=new_cam_info.image_name, uid=id)\n",
    "new_image = render_image(rotated_model, new_camera, white_backgrund=False) # hwc\n",
    "plt.imshow(new_image)\n",
    "plt.draw()\n",
    "# cameras = [new_camera]\n",
    "# visualize_camera_and_gaussians(cameras, rotated_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. rotate camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def rotate_camera(cam_position, cam_rotation, obj_position, rotmat):\n",
    "    translated_position = cam_position - obj_position\n",
    "    translated_position = translated_position @ rotmat.T\n",
    "    new_cam_position = translated_position + obj_position\n",
    "    new_cam_rotation = rotmat @ cam_rotation\n",
    "    return new_cam_position, new_cam_rotation\n",
    "\n",
    "\n",
    "angle_degrees = 90\n",
    "angle_radians = np.deg2rad(angle_degrees)\n",
    "rotation = Rotation.from_euler('x', angle_radians)\n",
    "rotmat = np.linalg.inv(rotation.as_matrix())\n",
    "model_center = torch.mean(model.get_xyz, dim=0).detach().cpu().numpy()\n",
    "cam_w2c = np.eye(4)\n",
    "cam_w2c[:3, :3] = cam_info.R.transpose()\n",
    "cam_w2c[:3,  3] = cam_info.T\n",
    "cam_c2w = np.linalg.inv(cam_w2c)\n",
    "cam_position = cam_c2w[:3,  3]\n",
    "cam_rotation = cam_c2w[:3, :3]\n",
    "\n",
    "rotated_position, rotated_rotation = rotate_camera(cam_position, cam_rotation, model_center, rotmat)\n",
    "rotated_cam_c2w = np.eye(4)\n",
    "rotated_cam_c2w[:3, :3] = rotated_rotation\n",
    "rotated_cam_c2w[:3,  3] = rotated_position\n",
    "rotated_cam_w2c = np.linalg.inv(rotated_cam_c2w)\n",
    "\n",
    "# Camera类输入参数的R和T需要特别注意，R为camera to world的旋转矩阵，T为world to camera的平移向量, 3DGS原始代码就是这样定义的\n",
    "rotated_camera = Camera(colmap_id=cam_info.uid, R=rotated_rotation, T=rotated_cam_w2c[:3,  3], \n",
    "                FoVx=cam_info.FovX, FoVy=cam_info.FovY, \n",
    "                image=torch.zeros((3,cam_info.height, cam_info.width)), gt_alpha_mask=None,\n",
    "                image_name=cam_info.image_name, uid=id)\n",
    "\n",
    "rotate_camera_image = render_image(model, rotated_camera, white_backgrund=False) # hwc\n",
    "plt.imshow(rotate_camera_image)\n",
    "plt.draw()\n",
    "# cameras = [rotated_camera]\n",
    "# visualize_camera_and_gaussians(cameras, model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def PSNR(img1, img2):\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "\n",
    "    pixel_max = 1\n",
    "    psnr = 20 * np.log10(pixel_max / np.sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "# print(\"all close: \", np.allclose(rotate_gaussians_image, rotate_camera_image, atol=1e-6))\n",
    "print(\"MSE:  \", np.abs(rotate_gaussians_image-rotate_camera_image).mean())\n",
    "print(\"PSNR: \", PSNR(rotate_gaussians_image, rotate_camera_image))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit: Tranlate gaussian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from copy import deepcopy\n",
    "\n",
    "@torch.no_grad()\n",
    "def translate_gaussians(gaussians, translate):\n",
    "    new_xyz = gaussians.get_xyz\n",
    "    new_xyz = new_xyz + translate[None]\n",
    "    gaussians._xyz = new_xyz\n",
    "\n",
    "translate = torch.tensor([5,0,0], device=model.get_xyz.device)\n",
    "translated_model = deepcopy(model) \n",
    "translate_gaussians(translated_model, translate)\n",
    "\n",
    "translated_image = render_image(translated_model, camera, white_backgrund=False) # hwc\n",
    "plt.imshow(translated_image)\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit: Scale gaussian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from copy import deepcopy\n",
    "\n",
    "@torch.no_grad()\n",
    "def scale_gaussians(gaussians, scale):\n",
    "    # scale gaussians potsition\n",
    "    new_xyz = gaussians.get_xyz\n",
    "    mean_xyz = torch.mean(new_xyz,0)\n",
    "    new_xyz = new_xyz - mean_xyz\n",
    "    new_xyz = new_xyz * scale[None]\n",
    "    gaussians._xyz = new_xyz + mean_xyz\n",
    "\n",
    "    # scale gaussians scale\n",
    "    new_scaling = torch.exp(gaussians._scaling) * scale[:2][None]\n",
    "    gaussians._scaling = torch.log(new_scaling)\n",
    "    \n",
    "scale = torch.tensor([2,2,2], device=model.get_xyz.device)\n",
    "scaled_model = deepcopy(model) \n",
    "scale_gaussians(scaled_model, scale)\n",
    "scaled_model.save_ply(path=\"./output.ply\")\n",
    "\n",
    "scaled_image = render_image(scaled_model, camera, white_backgrund=False) # hwc\n",
    "plt.imshow(scaled_image)\n",
    "plt.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surfel_splatting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
